\documentclass[10pt,showpacs,preprintnumbers,footinbib,amsmath,amssymb,aps,prl,twocolumn,groupedaddress,superscriptaddress,showkeys]{revtex4-1}
\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage[colorlinks=true,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{color}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{fancyref}

\newcommand{\pd}[2]{\frac{\partial#1}{\partial #2}}
\newcommand{\pdd}[2]{\frac{\partial^2#1}{\partial #2^2}}
\newcommand{\D}{\mathrm d}
 \newcommand{\ang}[1]{\left\langle #1 \right\rangle}
 \newcommand{\intinf}{\int\limits_{-\infty}^{\infty}}

\newcommand{\brac}[1]{\left[ #1\right] }
\newcommand{\paran}[1]{\left( #1 \right) }
\newcommand{\der}[2]{\frac{\mathrm d#1}{\mathrm d #2}}
\newcommand{\pder}[2]{\frac{\partial#1}{\partial#2}}

\newcommand{\suml}[2]{\sum\limits_{#1}^{#2}}
\newcommand{\Exp}[1]{e^{#1}}
\newcommand{\magnitude}[1]{\times 10^{#1}}
\newcommand{\dder}[2]{\frac{\mathrm d^2 #1}{\mathrm d^2 #2}}

\renewcommand{\d}{\mathrm d}
\newcommand{\up}{\uparrow}
\newcommand{\dw}{\downarrow}
\newcommand{\tvec}[2]{\begin{pmatrix} #1\\#2 \end{pmatrix}}
\newcommand{\eps}{\epsilon}
\newcommand{\dV}{\mathrm d V}
\newcommand{\dP}{\mathrm d P}
\newcommand{\dS}{\mathrm d S}
\newcommand{\dT}{\mathrm d T}
\newcommand{\dN}{\mathrm d N}
\newcommand{\dU}{\mathrm d U}
\newcommand{\dH}{\mathrm d H}
\newcommand{\dG}{\mathrm d G}
\newcommand{\dF}{\mathrm d F}
\newcommand{\dPh}{\mathrm d \Phi}
\newcommand{\ave}[1]{\langle #1\rangle}
\newcommand{\Z}{\mathcal Z}
\newcommand{\nfd}{\bar n_{\rm FD}}
\newcommand{\nbe}{\bar n_{\rm BE}}
\newcommand{\nbolt}{\bar n_{\rm Boltzm.}}
\newcommand{\npl}{\bar n_{\rm Planck}}

\graphicspath{{/home/espen/Documents/UiO/M1/FYS4150/project4/all_results/plots//}}


\begin{document}



\title[CPP2]{Computational Physics Project 4}

\author{Espen Hodne} 
\affiliation{Institute of Theoretical Astrophysics, University of Oslo}


\begin{abstract}

A nice abstract.

\end{abstract}



\maketitle



\section{Introduction}

The Ising model is a phase transition model that excels in one- and two-dimensional problems. At a given critical temperature, the model can show a phase transition from a magnetic phase to one with zero magnetization. The model's energy can be generally given as

\begin{equation}
E = -J\suml{<kl>}{N}s_k s_l
\end{equation}

with $s_k = \pm 1$, N is the total number of spins, and $\langle kl \rangle$ means that we only sum over nearest neighbors. That is, some combinations are incompatible, and will not be used together. The result of this can be seen in table \ref{tab:energies}.

In our use of the model, we assume a ferromagnetic ordering with $J > 0$. We also use periodic boundary conditions and the Metropolis algorithm.

\section{Methods and Algorithms} %\label{methods}


\subsection*{4a}

\begin{table}[!h]
\caption{List of spin configurations with energy and magnetic moment}
\begin{tabular}{|l|l|l|l|}
\hline
Number of up-spins & Degeneracy & Energy & Magnetization\\
\hline
4&1&-8J&4\\
\hline
3&4&0&2\\
\hline
2&4&0&0\\
\hline
2&2&8J&0\\
\hline
1&4&0&-2\\
\hline
0&1&-8J&-4\\
\hline
\end{tabular}
\label{tab:energies}
\end{table}


First, I solve the equations for energy $E$, mean magnetization $|M|$, specific heat $C_V$ and susceptibility $\chi$ analytically. These results give me a benchmark for which to measure the numerical results, and see if the program reproduces them within the boundaries of reasonability.

\begin{equation}
\left\langle E \right\rangle = \frac{1}{Z} \suml{i = 1}{M} E_i\Exp{-\beta E_i}
\label{eq:<E>}
\end{equation}

\begin{equation}
C_v = \frac{1}{k_B T^2}\left( \langle E^2 \rangle - \langle E \rangle ^2  \right)
\label{eq:C_V}
\end{equation}

\begin{equation}
\langle M \rangle = \frac{1}{Z}\suml{i}{M}M_i\Exp{-\beta E_i}
\label{eq:<M>}
\end{equation}

\begin{equation}
\chi = \frac{1}{k_B T}\left( \langle M^2 \rangle - \langle M \rangle ^2  \right)
\label{eq:chi}
\end{equation}

with the partition function $Z$ given as

\begin{equation}
Z = \sum_{i=1}^{M} e^{-\beta E_i}
\end{equation}



In this project, I use units of $\frac{k T}{J}$, so for all calculations the constants disappear.

Using a $L = 2$, or in other words a $2x2$ spin matrix will give us a sum of 16 ($S = 2^{2x2}$) energies/magnetizations to handle. This gives

$$
Z = \sum_{i=1}^{16} e^{-E_i/T}
$$
Inserting the energies seen in Table \ref{tab:energies} gives us
\begin{align*}
Z&= 12e^{0}+2e^{-8/T}+2e{8/T}\\
Z&= 12 + 4\cosh(\frac{8}{T}).
\end{align*}

Using this, we can calculate the mean energy

\begin{align*}
\langle E\rangle &=  \frac{1}{Z} \sum_{i=1}^{M} E_i e^{\beta E_i}\\
&= \frac{1}{Z} \sum_{i=1}^{M} E_i e^{E_i/T}\\
&= \frac{2\cdot 8e^{-8/T} -2\cdot 8e^{8/T}}{Z}\\
\langle E\rangle &= -\frac{8\sinh(8/T)}{3+\cosh(8/T)}.
\end{align*}

To calculate the specific heat capacity $C_V$ we need $\langle E^2\rangle$: 

\begin{align*}
\langle E^2 \rangle &= \frac{1}{Z}\sum_{1}^{16} E_i^2 e^{-E_i/T}\\
&= \frac{ 128e^{-8/T} + 128e^{8/T}}{Z}\\
 &= \frac{ 256\cosh(8/T)}{Z}\\
\langle E^2 \rangle &= \frac{64\cosh(8/T)}{3+\cosh(8/T)}\\
\end{align*}

This gives, at a constant value, specific heat capacity

\begin{align*}
C_V &= \frac{1}{k_B T^2}(\langle  E^2 \rangle - {\langle  E  \rangle}^2)\\
C_V &= (\frac{64}{T^2})\frac{(1+3\cosh(8/T))}{(3+\cosh(8/T))^2} 
\end{align*}

Next, I calculate the mean magnetization

\begin{align*}
\langle |M| \rangle &= \frac{1}{Z} \sum_{i}^{M} | M_i | e^{-\beta E_i}\\
&= \frac{1}{Z} \sum_{i}^{M} | M_i | e^{-\beta E_i}\\
\langle |M| \rangle &= \frac{4e^{8}+8+8+4e^{8}}{Z}\\
\langle |M| \rangle &= \frac{2(2+e^{8})}{3+\cosh(8/T)}\\
\end{align*}

To calculate the magnetic susceptibility $\chi$ I need the mean of the square magnetization:

\begin{align*}
\langle M^2 \rangle &= \frac{1}{Z} \sum_{1}^{16} M_i^2 e^{-E_i/T}\\
\langle M^2 \rangle &= \frac{16e^{8}+16+16+16e^{8}}{Z}\\
\langle M^2 \rangle &= \frac{8(1+e^{8})}{3+\cosh(8/T)}\\
\end{align*}

The magnetic susceptibility then becomes

\begin{align*}
\chi &= \frac{1}{k_B T^2}(\langle  M^2 \rangle - {\langle  M  \rangle}^2)\\
\chi &= \frac{4 (3 + 4 \cosh(8) + 2 \sinh(8))}{(3 + \cosh(8))^2}
\end{align*}


\subsection*{4b}

Next, I solve this numerically by using the Ising model and Metropolis sampling.

The use of Metropolis sampling for the two-dimensional Ising model can be summed up in nine steps, at a given temperature.

\paragraph{1)} Establish an initial state with energy $E_b$ by positioning yourself at a random configuration in the spin lattice.

\paragraph{2)} Change the initial configuration by flipping one spin. Then compute the energy of this "trial state" $E_t$.

\paragraph{3)} Calculate $\Delta E = E_t - E_b$.

\paragraph{4)} If $\Delta E \leq 0$, accept the new configuration, and go to step 7).. This means energy is lowered, and if we are lucky we move towards the energy minimum of the temperature.

\paragraph{5)} If $\Delta E > 0$, calculate $\omega = \Exp{-\beta\Delta E}$

\paragraph{6)} Compare $\omega$ with a random number $r$. If $r \leq \omega$, accept the new configuration. If not, keep the old configurations.

\paragraph{7)} Update the various expectation values.

\paragraph{8)} Repeat step 2)-7) by running multiple Monte Carlo simulations until your result is satisfactory.

\paragraph{9)} Divide by total number of cycles, and alternatively number of spins.

The previously mentioned Monte Carlo cycles are basically a numerical "measurement", equivalent to what could be done in a laboratory. Every time you sum over all spins, you have a Monte Carlo cycle.

I here again use a lattice with $L = 2x2$ spins, and try to recreate the analytical results.


To do all of this, I use a modified version of a program written by Morten Hjorth-Jensen.



\subsection*{4c}

Now that I know my program matches the analytical benchmarks, I can use it to do science. Specifically, I want to compare the cases where all spins have the same ordered direction, with the cases where the spins are randomized at the start. As the simulations progresses, we should see both configurations settle into a "most likely state."

Here, I set the ammount of spins up to $L = 20$, in order to get a more accurate result. I must trust that a program that works for $L = 2$ will also work for $L = 20$.

I calculate this both for the energy expectation values and for the mean magnetization, at temperatures $T = 1$ and $T = 2.4$. I am also interested in seeing how many configurations are actually accepted by the Metropolis sampling.



\subsection*{4d}

Next I look at the probability of finding certain energy values. I test for both ordered and random configurations, and for both $T = 1$ and $T = 2.4$.

I start at the point where the system has already become stable. That means that for $T = 1$, I start at the $10^4$th MC cycle, while for $T = 2.4$ I start at the $10^5$th. The probabilities can be seen in figures \ref{fig:4d_E_o_1} through \ref{fig:4d_E_r_2p4}.

\subsection*{4e}

The parallelized program was run three times. First from $T = 2 - 2.3$, then for $T = 2.31-2.6$ (both with timestep $dT = 0.01$), and finally from $T = 2.25-2.3$ with $dT = 0.001$.

\subsection*{4f}

\section{Results}

\subsection*{4a}

By inserting $T = 1$, and using units of $\frac{k T}{J}$, we get the following analytical results. 
$$
\langle E \rangle = -7.984
$$

$$
C_V = 0.1284
$$

$$
|M| = 3.9948
$$

$$
\chi = 0.016
$$

\subsection*{4b}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{EMC_vs_exact.png}
	\caption{Energy expectation value per Monte Carlo cycle compared to the exact value.}
	\label{fig:4b_E_exact}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{CVMC_vs_exact.png}
	\caption{Energy variance per Monte Carlo cycle compared to the exact value.}
	\label{fig:4b_CV_exact}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{MMC_vs_exact.png}
	\caption{Absolute magnetization value per Monte Carlo cycle compared to the exact value.}
	\label{fig:4b_Mabs_exact}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{chiMC_vs_exact.png}
	\caption{Suceptibility per Monte Carlo cycle compared to the exact value.}
	\label{fig:4b_chi_exact}
\end{figure}

It is important to note that the exact values here are per spin, so with $L = 2$ they are a fourth of the calculated analytical values.

%\begin{table}[]
%\centering
%\caption{Results for $1-10^7$ Monte Carlo simulations for $T = 1$ and $L = 2\times 2$}
%\label{tab:4b_results}
%\begin{tabular}{c|c|c|c|c|c}
%MC & $\langle E \rangle$ & $C_V$       & $\langle M \rangle$ & $\chi$       & $|M|$ \\
%\hline
%\hline
%1              & -2.0000000          & 0.000000000 & 1.00000000          & 0.0000000000 & 1.00000000            \\
%10             & -2.0000000          & 0.000000000 & 1.00000000          & 0.0000000000 & 1.00000000            \\
%100            & -2.0000000          & 0.000000000 & 1.00000000          & 0.0000000000 & 1.00000000            \\
%$10^3$         & -1.9980000          & 0.015984000 & 0.53650000          & 0.0009990000 & 0.99950000            \\
%$10^4$         & -1.9930000          & 0.055804000 & -0.001650000        & 0.0082739900 & 0.99745000            \\
%$10^5$         & -1.9964000          & 0.028748160 & -0.045280000        & 0.0033546176 & 0.99884000            \\
%$10^6$         & -1.9958960          & 0.032764629 & -0.031973000        & 0.0041444265 & 0.99862400            \\
%$10^7$         & -1.9959584          & -1.99595842 & 0.0084731000        & 0.0040459197 & 0.99865090           
%\end{tabular}
%\end{table}

\subsection*{4c}



$\langle E \rangle$:

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4c_MC_E.png}
	\caption{Energy expectation value per Monte Carlo cycle.}
	\label{fig:4c_MC_E}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4c_MC_Mabs.png}
	\caption{Absolute magnetization value per Monte Carlo cycle.}
	\label{fig:4c_MC_Mabs}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4c_MC_config.png}
	\caption{Number of configurations accepted by the Metropolis algorithm as a function of Monte Carlo cycles.}
	\label{fig:4c_MC_config}
\end{figure}

\subsection*{4d}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4d_hist_E_o_1_steady.png}
	\caption{Energy configuration probabilities for an ordered spin state, with temperature $T = 1$.}
	\label{fig:4d_E_o_1}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4d_hist_E_r_1_steady.png}
	\caption{Energy configuration probabilities for an random spin state, with temperature $T = 1$.}
	\label{fig:4d_E_r_1}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4d_hist_E_o_2p4_steady.png}
	\caption{Energy configuration probabilities for an ordered spin state, with temperature $T = 2.4$.}
	\label{fig:4d_E_o_2p4}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4d_hist_E_r_2p4_steady.png}
	\caption{Energy configuration probabilities for an random spin state, with temperature $T = 2.4$.}
	\label{fig:4d_E_r_2p4}
\end{figure}

The final values of the energy variance are $C_V = 0.023$ for $T = 1$ and $C_V = 1.41$ for $T = 2.4$.

\subsection*{4e}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4e_T_E.png}
	\caption{Energy expectation value $\langle E \rangle$ as a function of temperature.}
	\label{fig:4e_Energy}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4e_T_Mabs.png}
	\caption{Absolute magnetization $\langle |M| \rangle$ as a function of temperature.}
	\label{fig:4e_Mabs}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4e_T_CV.png}
	\caption{Energy variance $C_V$ as a function of temperature.}
	\label{fig:4e_CV}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4e_T_chi.png}
	\caption{Susceptibility $\chi$ as a function of temperature.}
	\label{fig:4e_chi}
\end{figure}


\subsection*{4f}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4f_extrap_blunt.png}
	\caption{Critical temperature, with timestep $dT = 0.01$}
	\label{fig:4f_blunt}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{4f_extrap_sharp.png}
	\caption{Critical temperature, with timestep $dT = 0.001$}
	\label{fig:4e_chi}
\end{figure}


The numbers calculated were $T_C = 2.2832$ for $dT = 0.01$ and $T_C = 2.2937$ for $dT = 0.001$.

The run times were the following:

\begin{table}[]
\centering
\caption{Runtimes on the Institute of Theoretical Astrophysics Beehive cluster with 40 cores.}
\label{tab:runtimes}
\begin{tabular}{l|l|l}
        & \begin{tabular}[c]{@{}l@{}}$T_{end} - T_{start} = 0.3$\\ $dT = 0.01$\end{tabular} & \begin{tabular}[c]{@{}l@{}}$T_{end} - T_{start} = 0.05$\\ $dT = 0.001$\end{tabular} \\
\hline
40x40   & 157s                                                                              & 136s                                                                                \\
60x60   & 184s                                                                              & 305s                                                                                \\
80x80   & 332s                                                                              & 549s                                                                                \\
100x100 & 521s                                                                              & 863s                                                                               
\end{tabular}
\end{table} 


\section{Conclusions and Discussion}

\subsection*{4a}

The analytical results themselves are not of particular interest, what is more interesting to look at is how they compare to the numerical ones.


\subsection*{4b}

If we look at figures \ref{fig:4b_E_exact} through \ref{fig:4b_chi_exact}, we see that the computed values of $\langle E \rangle$, $C_V$, $|M|$ and $\chi$ approaches the exact values at a different ammount of Monte Carlo cycles.

However, not matter how they differ, we must adapt to the value that needs the most MC simulations. That seem to be $\langle E \rangle$. As we can see in the figures, all variables have settled nicely after $\approx 10^6$ simulations. Thus, $10^6$ is my go-to number in the entire project.

\subsection*{4c}

Figures \ref{fig:4c_MC_E} and \ref{fig:4c_MC_Mabs} shows how the energy expectation values and absolute magnetization changes based on number of Monte Carlo simulations, for temperatures $T = 1$ and $T = 2.4$. 

As we can see, the ordered simulation for the low temperature is at the most likely sate immediately. This is because at low temperatures, the system will not have much energy to "jump around". Figure \ref{fig:4c_MC_E} shows that the random configuration for $T = 1$ also rather quickly settles down to an equilibrium, at around $MC = 4\magnitude{3}$.

However, for higher temperatures, the energies of both configurations will oscillate, before they settle at round $MC = 10^5$.

The situation seem similar for the magnetization in figure \ref{fig:4c_MC_Mabs}, with the difference being that the system (obviously) settles on different values.

As detailed above, not all configurations will be accepted. I therefore also plot the number of accepted configuration per MC cycle, as can be seen in figure \ref{fig:4c_MC_config}. It is important to note here that the plot is logarithmic. Unsurprisingly, as we use more MC cycles, more configurations are accepted, as they get closer to the equilibrium situantion. However, a notable difference between the temperatures is that first and foremost, the $T = 2.4$ system accepts many more  configurations than the low-temperature one. This shows that the number of accepted configuration scales exponentially with temperature.

Another thing to note is that for the low-temperature system, initially the random configurations get accepted much more often than the ordered ones. At the high-temperature ones, both kinds of configurations are accepted an almost identical ammount of times.

\subsection*{4d}

When the system is in equilibrium, the energy variance is small. This is extremely visible in figures \ref{fig:4d_E_o_1} and \ref{fig:4d_E_r_1}. The great majority of energies is at the equilibrium value.

Figures \ref{fig:4d_E_o_2p4} and \ref{fig:4d_E_r_2p4} tell a different story. For the higher temperatures, the system is much more chaotic. This is an inherent physical property that stems from the randomness in a quantum-mechanical system. Like many physical probability distributions, ours settles neatly into a Gaussian curve.

A thing to note is that there is virtually no difference between the random and ordered configurations. This is good, because it means the system settles into an equilibrium, regardless of how our initial spins are assigned.

The computed energy variance is $0.023$ for $T = 1$ and $1.41$ for $T = 2.4$. This alone should show that the probabilites I get are reasonable. These results also match very well with what is observed in the histograms.
 
\subsection*{4e}

\subsection*{4f}



\section{Extra Material}
You can find the code we used to calculate these results at: 

\begin{thebibliography}{99}
\bibitem{taut}\href{http://prola.aps.org/abstract/PRA/v48/i5/p3561_1}{M. Taut, Phys. Rev. A 48, 3561 (1993)}
%\bibitem{jensen} M.~H.Ìƒ~Jensen, Computational~Physics(11.09.2017) \url{github.com/CompPhysics/ComputationalPhysics/blob/master/doc/Projects/2017/ReportExamplesLatexstyle/reportexample.tex}
\end{thebibliography}

\end{document}